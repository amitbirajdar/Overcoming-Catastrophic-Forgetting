{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "EWConMNIST.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "vg3tQNe9989l"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSLIvmiq9hHS"
      },
      "source": [
        "'''Importing necessary libraries'''\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras import utils as np_utils\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.python.framework.ops import disable_eager_execution\n",
        "\n",
        "import numpy as np\n",
        "from numpy import random\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGZVtOAUoEQ1"
      },
      "source": [
        "disable_eager_execution()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOjv6Eli5f93"
      },
      "source": [
        "random.seed(7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnmblXIy9vib"
      },
      "source": [
        "'''loading MNIST dataset'''\n",
        "\n",
        "(x_trainA, y_trainA), (x_testA, y_testA) = mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jse1kI9kpOXf"
      },
      "source": [
        "'''Concatenating into one single data for preprocessing'''\n",
        "\n",
        "X = np.concatenate((x_trainA,x_testA), axis=0)\n",
        "Y = np.concatenate((y_trainA,y_testA), axis=0)\n",
        "\n",
        "X.shape, Y.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEuxeHm6v1P4"
      },
      "source": [
        "'''Normalizing the pixel values'''\n",
        "\n",
        "X = X / 255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFNsM2B-93ff"
      },
      "source": [
        "'''splitting MNIST into two partitions (0-4) and (5-9)'''\n",
        "\n",
        "'''Getting indexes '''\n",
        "idx0_4, idx5_9 = [], []\n",
        "\n",
        "for i in range(0,10):\n",
        "  if i < 5:\n",
        "    idx0_4.append(np.where(Y==i)) # filter mnist data for 0-4\n",
        "  else:\n",
        "    idx5_9.append(np.where(Y==i)) # filter mnist data for 5-9"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hB3JlIC3uKPb"
      },
      "source": [
        "'''Combining labels for the two partitions'''\n",
        "\n",
        "index0_4 = np.concatenate((idx0_4[0][0], idx0_4[1][0], idx0_4[2][0], idx0_4[3][0], idx0_4[4][0]), axis=0)\n",
        "index5_9 = np.concatenate((idx5_9[0][0], idx5_9[1][0], idx5_9[2][0], idx5_9[3][0], idx5_9[4][0]), axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xixefae4y4ql"
      },
      "source": [
        "'''Getting labels'''\n",
        "\n",
        "y0_4 = Y[index0_4]\n",
        "y5_9 = Y[index5_9]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rt_Js5Qks_Eg"
      },
      "source": [
        "'''Getting corresponding images'''\n",
        "\n",
        "img0_4 = X[[index0_4]] # get mnist data for 0-4\n",
        "img5_9 = X[[index5_9]] # get mnist data for 5-9\n",
        "\n",
        "img0_4.shape, img5_9.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEwF4mUmLwkr"
      },
      "source": [
        "'''Creating a MLP'''\n",
        "\n",
        "def create_model():\n",
        "  model = models.Sequential([\n",
        "      layers.Dense(800, input_dim = 784, activation='relu'),\n",
        "      layers.Dropout(0.5),\n",
        "      layers.Dense(800, activation='relu'),\n",
        "      layers.Dropout(0.5),\n",
        "      layers.Dense(800, activation='relu'),\n",
        "      layers.Dropout(0.5),\n",
        "      layers.Dense(5, activation='softmax')\n",
        "  ])\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9oSBw92Jxcvi"
      },
      "source": [
        "'''Setting up optimizer'''\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "opt = SGD(lr=0.05)\n",
        "batch_size = 64\n",
        "patience = 5\n",
        "clipgrad = 10000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCW_Dw2P-hqS"
      },
      "source": [
        "'''Function for plotting training and validation accuracy'''\n",
        "\n",
        "def plot(history):\n",
        "  plt.plot(history.history['accuracy'])\n",
        "  plt.plot(history.history['val_accuracy'])\n",
        "  plt.legend(['acc', 'val_acc'])\n",
        "  plt.grid(True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skcnjAFXZwXc"
      },
      "source": [
        "'''Function to compile and fit model'''\n",
        "\n",
        "def compile_and_fit(model, xa, xb, validation_data, epochs, loss, filename):\n",
        "  model.compile(optimizer = opt, loss=loss, metrics=['accuracy'])\n",
        "  history = model.fit(xa, xb, epochs=epochs, validation_data=validation_data)\n",
        "  model.save_weights(f'/content/drive/MyDrive/552 PROJECT/EWConMNIST/{filename}.h5')\n",
        "  return model, history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1H_fCuQD4Jxq"
      },
      "source": [
        "'''Computing Fisher Matrix and creating regularizers'''\n",
        "'''Fisher natrix calculation referred from the following repository'''\n",
        "'''https://github.com/King-Of-Knights/overcoming-catastrophic'''\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import keras.backend as K\n",
        "from keras.regularizers import Regularizer\n",
        "\n",
        "def fisher_information(model, validation_set, samples=30):\n",
        "    fisher_matrix = []\n",
        "\n",
        "    # initializing f_accum\n",
        "    for i in range(len(model.weights)):\n",
        "        fisher_matrix.append(np.zeros(K.int_shape(model.weights[i])))\n",
        "        # fisher_matrix.append(np.zeros(model.weights[i])) # new\n",
        "\n",
        "    \n",
        "    fisher_matrix = np.array(fisher_matrix)\n",
        "\n",
        "    for j in range(samples):\n",
        "        # pick an image at random\n",
        "        index = np.random.randint(validation_set.shape[0]) \n",
        "\n",
        "        for m in range(len(model.weights)):\n",
        "\n",
        "            # returns gradient of loss function w.r.t weights\n",
        "            grads = K.gradients(K.log(model.output), model.weights)[m]\n",
        "            # K.log(model.output) -> loss calculated on the output layer (softmax)\n",
        "            \n",
        "            result = K.function([model.input], [grads])\n",
        "            \n",
        "            fisher_matrix[m] += np.square(result([np.expand_dims(validation_set[index], 0)])[0])\n",
        "    \n",
        "    fisher_matrix = fisher_matrix / samples\n",
        "    return fisher_matrix\n",
        "\n",
        "class ewc_reg(Regularizer):\n",
        "    def __init__(self, fisher, prior_weights, Lambda=0.1):\n",
        "        self.fisher = fisher\n",
        "        self.prior_weights = prior_weights\n",
        "        self.Lambda = Lambda\n",
        "\n",
        "    def __call__(self, x):\n",
        "        regularization = 0.\n",
        "        regularization += self.Lambda * K.sum(self.fisher * K.square(x - self.prior_weights))\n",
        "        return regularization\n",
        "\n",
        "    def get_config(self):\n",
        "        return {'Lambda': float(self.Lambda)}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXMD3GcrvihV"
      },
      "source": [
        "# Task 1: Training on MNIST (0-4)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9njd5HxH-nH"
      },
      "source": [
        "'''Setting up X and Y for the first task'''\n",
        "\n",
        "X0_4 = img0_4\n",
        "Y0_4 = y0_4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_YgXjdWfv54R"
      },
      "source": [
        "'''Splitting the data into training and testing data'''\n",
        "\n",
        "x_train0_4, x_test0_4, y_train0_4, y_test0_4 = train_test_split(X0_4, Y0_4, test_size=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFCGMqPawY8v"
      },
      "source": [
        "x_train0_4.shape, y_train0_4.shape, x_test0_4.shape, y_test0_4.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPRTGEvEtube"
      },
      "source": [
        "'''reshaping inputs to feed to dense layer of network'''\n",
        "\n",
        "x_train0_4 = x_train0_4.reshape((-1, 784))\n",
        "x_test0_4 = x_test0_4.reshape((-1, 784))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9drlTUFPDSSH"
      },
      "source": [
        "model0_4 = create_model()\n",
        "model0_4.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQ1_3J0fEY15"
      },
      "source": [
        "'''Compiling and training the model on task 1'''\n",
        "'''Save weights for initializing the next model'''\n",
        "\n",
        "model0_4, history0_4 = compile_and_fit(model0_4, x_train0_4, y_train0_4, (x_test0_4, y_test0_4), 50, 'sparse_categorical_crossentropy', 'task1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFn5W_PKGKxY"
      },
      "source": [
        "plot(history0_4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3BCQywIcg74"
      },
      "source": [
        "acc_after_task1 = round(model0_4.evaluate(x_test0_4, y_test0_4)[1] * 100 , 2)\n",
        "acc_after_task1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JyCZZy4Q3QNV"
      },
      "source": [
        "# Task 2: Training on MNIST (5-9)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNKTTdxa3So-"
      },
      "source": [
        "'''Setting up X and Y for the second task'''\n",
        "\n",
        "X5_9 = img5_9\n",
        "Y5_9 = y5_9"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5iQkcrd0Rz88"
      },
      "source": [
        "'''Encoding labels 5-9 into 0-4 since the model's last dense (softmax) wont accept values starting from 5'''\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "encoder = LabelEncoder()\n",
        "y5_9 = encoder.fit_transform(Y5_9)\n",
        "y5_9"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yy26ZLgg4p14"
      },
      "source": [
        "Y5_9"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLWwgfc-3b0r"
      },
      "source": [
        "'''Splitting the data into training and testing data'''\n",
        "\n",
        "x_train5_9, x_test5_9, y_train5_9, y_test5_9 = train_test_split(X5_9, y5_9, test_size=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7RqFm6d3bxi"
      },
      "source": [
        "x_train5_9.shape, y_train5_9.shape, x_test5_9.shape, y_test5_9.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8P9hI-Tr3bhF"
      },
      "source": [
        "'''reshaping inputs to feed to dense layer of network'''\n",
        "\n",
        "x_train5_9 = x_train5_9.reshape((-1, 784))\n",
        "x_test5_9 = x_test5_9.reshape((-1, 784))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUC2vQ-o4XpL"
      },
      "source": [
        "F1 = fisher_information(model0_4, x_test0_4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1d2OIl0LfSpO"
      },
      "source": [
        "model5_9 = models.Sequential([\n",
        "    layers.Dense(800, input_dim = 784, activation='relu', kernel_regularizer=ewc_reg(F1[0], model0_4.weights[0]), bias_regularizer=ewc_reg(F1[1], model0_4.weights[1])),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(800, activation='relu', kernel_regularizer = ewc_reg(F1[2], model0_4.weights[2]), bias_regularizer = ewc_reg(F1[3], model0_4.weights[3])),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(800, activation='relu', kernel_regularizer = ewc_reg(F1[4], model0_4.weights[4]), bias_regularizer = ewc_reg(F1[5], model0_4.weights[5])),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(5, activation='softmax', kernel_regularizer=ewc_reg(F1[6], model0_4.weights[6]), bias_regularizer=ewc_reg(F1[7], model0_4.weights[7]))\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7L5YRGdS34Lj"
      },
      "source": [
        "'''compiling and training the model for task 2'''\n",
        "'''Load weights from the previous task so that same model is used'''\n",
        "'''Save weights for initializing the next model'''\n",
        "\n",
        "model5_9.compile(optimizer=opt, loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "model5_9.load_weights('/content/drive/MyDrive/552 PROJECT/EWConMNIST/task1.h5')\n",
        "\n",
        "history5_9 = model5_9.fit(x_train5_9, y_train5_9, epochs=50, validation_data = (x_test5_9, y_test5_9))\n",
        "\n",
        "model5_9.save_weights('/content/drive/MyDrive/552 PROJECT/EWConMNIST/task2.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRPeF-ni34I5"
      },
      "source": [
        "'''Plotting the accuracy over training period'''\n",
        "plot(history5_9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x95emNGcmKRI"
      },
      "source": [
        "model5_9.evaluate(x_test0_4, y_test0_4)[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9yDn-1-ccr7j"
      },
      "source": [
        "# Task 3: training on shuffled (pixel shuffling) images (mnist 0-4)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jw3Qfz7YVgKD"
      },
      "source": [
        "'''Setting up X and Y for the third task'''\n",
        "\n",
        "pX0_4 = img0_4\n",
        "pY0_4 = y0_4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DrvIYeSpe5tS"
      },
      "source": [
        "'''Shuffling the pixels'''\n",
        "\n",
        "i = np.arange(pX0_4.shape[1])\n",
        "np.random.shuffle(i)\n",
        "\n",
        "pX0_4 = pX0_4[:, i]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1OWjmHqggko"
      },
      "source": [
        "'''visualizing the shuffled images'''\n",
        "\n",
        "plt.subplot(2,2,3)\n",
        "plt.imshow(img0_4[9883].reshape(28,28), cmap='gray')\n",
        "plt.xlabel(y0_4[9883])\n",
        "plt.xticks([])\n",
        "plt.yticks([])\n",
        "\n",
        "plt.subplot(2,2,4)\n",
        "plt.imshow(pX0_4[9883].reshape(28,28), cmap='gray')\n",
        "plt.xlabel(pY0_4[9883])\n",
        "plt.xticks([])\n",
        "plt.yticks([])\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRPEwg-iWYyC"
      },
      "source": [
        "'''splitting data into training and testing data'''\n",
        "\n",
        "pX_train0_4, pX_test0_4, pY_train0_4, pY_test0_4 = train_test_split(pX0_4, pY0_4, test_size=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mzawtgBWzLq"
      },
      "source": [
        "'''reshaping inputs to feed to dense layer of network'''\n",
        "\n",
        "pX_train0_4 = pX_train0_4.reshape((-1, 784))\n",
        "pX_test0_4 = pX_test0_4.reshape((-1, 784))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6uHHTghh9mys"
      },
      "source": [
        "F2 = fisher_information(model5_9, x_test5_9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kkQttXPkm9l"
      },
      "source": [
        "'''creating a new model'''\n",
        "\n",
        "modelp0_4 = models.Sequential([\n",
        "    layers.Dense(800, input_dim = 784, activation='relu', kernel_regularizer=ewc_reg(F2[0], model5_9.weights[0]), bias_regularizer=ewc_reg(F2[1], model5_9.weights[1])),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(800, activation='relu', kernel_regularizer = ewc_reg(F2[2], model5_9.weights[2]), bias_regularizer = ewc_reg(F2[3], model5_9.weights[3])),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(800, activation='relu', kernel_regularizer = ewc_reg(F2[4], model5_9.weights[4]), bias_regularizer = ewc_reg(F2[5], model5_9.weights[5])),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(5, activation='softmax', kernel_regularizer=ewc_reg(F2[6], model5_9.weights[6]), bias_regularizer=ewc_reg(F2[7], model5_9.weights[7]))\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mUpiNIwj_rQ"
      },
      "source": [
        "'''compiling and training the model for task 3'''\n",
        "'''Load weights from the previous task so that same model is used'''\n",
        "'''Save weights for initializing the next model'''\n",
        "\n",
        "modelp0_4.compile(loss='sparse_categorical_crossentropy', optimizer = opt, metrics=['accuracy'])\n",
        "\n",
        "modelp0_4.load_weights('/content/drive/MyDrive/552 PROJECT/EWConMNIST/task2.h5')\n",
        "\n",
        "historyp0_4 = modelp0_4.fit(pX_train0_4, pY_train0_4, epochs=50, validation_data = (pX_test0_4, pY_test0_4))\n",
        "\n",
        "modelp0_4.save_weights('/content/drive/MyDrive/552 PROJECT/EWConMNIST/task3.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0i0W5DajkyKt"
      },
      "source": [
        "'''Plotting the accuracy over training period'''\n",
        "plot(historyp0_4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UblwRliKX5Gz"
      },
      "source": [
        "# Task 4: training on shuffled (pixel shuffling) images (mnist 5-9)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2T7sO1hSYCa7"
      },
      "source": [
        "'''Setting up X and Y for the second task'''\n",
        "\n",
        "pX5_9 = img5_9\n",
        "pY5_9 = y5_9"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGVogkKhYCYE"
      },
      "source": [
        "'''Encoding labels 5-9 into 0-4 since the model's last dense (softmax) wont accept values starting from 5'''\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "encoder2 = LabelEncoder()\n",
        "pY5_9 = encoder2.fit_transform(pY5_9)\n",
        "pY5_9"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FthSShQYCVk"
      },
      "source": [
        "'''Shuffling the pixels'''\n",
        "\n",
        "i = np.arange(pX5_9.shape[1])\n",
        "np.random.shuffle(i)\n",
        "\n",
        "pX5_9 = pX5_9[:, i]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24ahl9-aYCS0"
      },
      "source": [
        "'''splitting data into training and testing data'''\n",
        "\n",
        "pX_train5_9, pX_test5_9, pY_train5_9, pY_test5_9 = train_test_split(pX5_9, pY5_9, test_size=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2kdTk8drYCPT"
      },
      "source": [
        "'''reshaping inputs to feed to dense layer of network'''\n",
        "\n",
        "pX_train5_9 = pX_train5_9.reshape((-1, 784))\n",
        "pX_test5_9 = pX_test5_9.reshape((-1, 784))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPqz1umZIPtv"
      },
      "source": [
        "F3 = fisher_information(modelp0_4, pX_test0_4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_nj7XHzYCNM"
      },
      "source": [
        "'''creating a new model'''\n",
        "\n",
        "modelp5_9 = models.Sequential([\n",
        "    layers.Dense(800, input_dim = 784, activation='relu', kernel_regularizer=ewc_reg(F3[0], modelp0_4.weights[0]), bias_regularizer=ewc_reg(F3[1], modelp0_4.weights[1])),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(800, activation='relu', kernel_regularizer = ewc_reg(F3[2], modelp0_4.weights[2]), bias_regularizer = ewc_reg(F3[3], modelp0_4.weights[3])),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(800, activation='relu', kernel_regularizer = ewc_reg(F3[4], modelp0_4.weights[4]), bias_regularizer = ewc_reg(F3[5], modelp0_4.weights[5])),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(5, activation='softmax', kernel_regularizer=ewc_reg(F3[6], modelp0_4.weights[6]), bias_regularizer=ewc_reg(F3[7], modelp0_4.weights[7]))\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJPO6tWvYCKh"
      },
      "source": [
        "'''compiling and training the model for task 3'''\n",
        "'''Load weights from the previous task so that same model is used'''\n",
        "'''Save weights for initializing the next model'''\n",
        "\n",
        "\n",
        "modelp5_9.compile(loss='sparse_categorical_crossentropy', optimizer = opt, metrics=['accuracy'])\n",
        "\n",
        "modelp5_9.load_weights('/content/drive/MyDrive/552 PROJECT/EWConMNIST/task3.h5')\n",
        "\n",
        "historyp5_9 = modelp5_9.fit(pX_train5_9, pY_train5_9, epochs=50, validation_data = (pX_test5_9, pY_test5_9))\n",
        "\n",
        "modelp5_9.save_weights('/content/drive/MyDrive/552 PROJECT/EWConMNISTtask4.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8WkTpFSYCIh"
      },
      "source": [
        "'''Plotting the accuracy over training period'''\n",
        "\n",
        "plot(historyp5_9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5-NOWVbZ0dD"
      },
      "source": [
        "# Checking accuracy change on Task A"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xd7WWZLWXFT4"
      },
      "source": [
        "original_acc = round(model0_4.evaluate(x_test0_4, y_test0_4)[1]*100 , 2)\n",
        "aftertask2 = round(model5_9.evaluate(x_test0_4, y_test0_4)[1]*100 , 2)\n",
        "aftertask3 = round(modelp0_4.evaluate(x_test0_4, y_test0_4)[1]*100 , 2)\n",
        "aftertask4 = round(modelp5_9.evaluate(x_test0_4, y_test0_4)[1]*100 , 2)\n",
        "accuracies = [original_acc, aftertask2, aftertask3, aftertask4]\n",
        "accuracies"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vsbJ6itZ4tj"
      },
      "source": [
        "fig, ax = plt.subplots()\n",
        "\n",
        "fig.set_size_inches(7, 5, forward=True)\n",
        "\n",
        "x = ['Original Accuracy', 'After Task 2', 'After Task 3', 'After Task 4']\n",
        "y = accuracies\n",
        "\n",
        "# Save the chart so we can loop through the bars below.\n",
        "bars = ax.bar(\n",
        "    x = x,\n",
        "    height=y,\n",
        "    tick_label=x\n",
        ")\n",
        "\n",
        "# Axis formatting.\n",
        "ax.spines['top'].set_visible(True)\n",
        "ax.spines['right'].set_visible(True)\n",
        "ax.spines['left'].set_visible(True)\n",
        "ax.spines['bottom'].set_color('#DDDDDE')\n",
        "ax.tick_params(bottom=False, left=True)\n",
        "ax.set_axisbelow(True)\n",
        "ax.yaxis.grid(True, color='#EEEEEE')\n",
        "ax.xaxis.grid(True)\n",
        "\n",
        "# Add text annotations to the top of the bars.\n",
        "bar_color = bars[0].get_facecolor()\n",
        "for bar in bars:\n",
        "  ax.text(\n",
        "      bar.get_x() + bar.get_width() / 2,\n",
        "      bar.get_height() + 0.3,\n",
        "      round(bar.get_height(), 1),\n",
        "      horizontalalignment='center',\n",
        "      color='black'\n",
        "      #weight='bold'\n",
        "  )\n",
        "\n",
        "# Add labels and a title. Note the use of `labelpad` and `pad` to add some\n",
        "# extra space between the text and the tick labels.\n",
        "#ax.set_xlabel('Different methods', labelpad=15, color='#333333')\n",
        "ax.set_ylabel('Accuracy', labelpad=15, color='#333333')\n",
        "ax.set_title('Demonstration of Catastrophic Forgetting', pad=15, color='#333333',\n",
        "             weight='bold')\n",
        "\n",
        "fig.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRsR8LDRbskH"
      },
      "source": [
        "\n",
        "plt.title('Accuracy of the model on task A')\n",
        "plt.plot([1,2,3,4], accuracies, color='blue', marker='o', linestyle='dashed', linewidth=2, markersize=12)\n",
        "plt.xticks([1,2,3,4])\n",
        "plt.xlabel('Tasks')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.grid(True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8Bj1ZS8CZdt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}